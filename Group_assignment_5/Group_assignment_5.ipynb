{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1cddfcf",
   "metadata": {},
   "source": [
    "# Segmentation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232887bd",
   "metadata": {},
   "source": [
    "## Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c33a3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from scipy.signal import convolve2d\n",
    "import cv2 \n",
    "from skimage.segmentation import chan_vese\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126af9c1",
   "metadata": {},
   "source": [
    "## k-means algorithm via lloyd's algorithm\n",
    "* For grey images\n",
    "* based on lloyds algorithm from slides\n",
    "* the feature used must be pixel intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fd7d907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Kmeans_lloyd(k, image, random_seed, patience = 2):\n",
    "\n",
    "    random.seed(random_seed) # set random seed\n",
    "\n",
    "    # ectract intensity values, the relative position of the pixels does not matter\n",
    "    shape = image.shape\n",
    "    pixels = image.flatten().reshape(-1,1) # 1d array of pixels, shape (N, 1)\n",
    "    centroids = np.random.uniform(pixels.min(), pixels.max(), size = k).reshape(1, -1) # shape (1, N)\n",
    "\n",
    "\n",
    "    change_count = 0 # part of the stopping condition\n",
    "\n",
    "    while True:\n",
    "\n",
    "        # compute distance for all points to all centroids\n",
    "        distances = np.abs(pixels - centroids) # (N,1) x (1, k) = (N , k)\n",
    "\n",
    "        #put each pixel in the cluster belonging to the nearest centroid\n",
    "        clusters = np.argmin(distances, axis= 1)\n",
    "\n",
    "        # recompute centroids (position)\n",
    "        new_centroids = np.zeros((1,k)) # empty numpy array\n",
    "        \n",
    "        for i in range(k):\n",
    "                cluster_pixels = pixels[clusters == i]\n",
    "                new_centroids[0, i] = cluster_pixels.mean()\n",
    "                    \n",
    "        \n",
    "\n",
    "        # STOPPING CONDITION\n",
    "        if np.allclose(new_centroids, centroids): # checks if the values have moved within a small margin. It returns True if the centroids have stopped moving\n",
    "            change_count += 1\n",
    "        else:\n",
    "            change_count =0\n",
    "\n",
    "        if change_count >= patience:\n",
    "            break\n",
    "\n",
    "        centroids = new_centroids\n",
    "    \n",
    "    # save points to points to clusters\n",
    "    clusters = clusters.reshape(shape)\n",
    "\n",
    "    return clusters, centroids\n",
    "\n",
    "def kmeans_segment(k , image, random_seed, patience = 2):\n",
    "    clusters, centroids = Kmeans_lloyd(k , image, random_seed, patience)\n",
    "\n",
    "    centroids_flat = centroids.flatten()\n",
    "\n",
    "    \n",
    "    segmented_image = centroids_flat[clusters]\n",
    "    return segmented_image\n",
    "\n",
    "\n",
    "\n",
    "def kmeans_segment_binary(k , image, random_seed, patience = 2):\n",
    "    \n",
    "    clusters, _ = Kmeans_lloyd(k , image, random_seed, patience)\n",
    "\n",
    "    binary_image = clusters.astype(np.uint8)\n",
    "\n",
    "    return binary_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9fb194",
   "metadata": {},
   "source": [
    "# Otsu thresholding algorithm\n",
    "* Based on the 1979_otsu_IEEESys.pdf document and the slides segmentation.pdf\n",
    "\n",
    "It was pretty hard to understand the algorithm, so i have written which equations i used from the 1979_otsu_IEEESys paper, when relevant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2273bcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def otsu(image):\n",
    "\n",
    "    # Compute histogram\n",
    "    histogram, bin_edges = np.histogram(image, bins=256, range=(0, 256))\n",
    "\n",
    "    # Normalize historgram and regard it as a probability distribution P(i) = h(i) /N\n",
    "    p_i = histogram / np.sum(histogram) \n",
    "\n",
    "    total_mean = np.sum(np.arange(256) * p_i)  # mean intensity of the image\n",
    "\n",
    "    max_variance = 0 # initial maximum variance\n",
    "    threshold = 0   # initial threshold\n",
    "    w0 = 0  # initial  probability for class 0\n",
    "    w1 = 0  # initial probability for class 1 \n",
    "    mu_k = 0.0\n",
    "    epsilon = 1e-10\n",
    "    L = len(p_i)  # number of bins = 256\n",
    "\n",
    "    for i in range(L):\n",
    "        w0 += p_i[i]  #  probability for class 0 cumulative (equation 2)\n",
    "        w1 = 1 - w0  #  probability for class 1 (equation 3)\n",
    "\n",
    "        if w0 < epsilon or w1 < epsilon: # makes sure we dont divide by zero:)\n",
    "            continue\n",
    "\n",
    "        mu_k += i * p_i[i]  # cumulative mean up to bin i\n",
    "\n",
    "        mu0 =  mu_k / w0  # mean for class 0 (equation 4)\n",
    "\n",
    "        mu1 = (total_mean - mu_k) / w1  # mean for class 1 (equation 5) \n",
    "\n",
    "        # Between class variance\n",
    "        variance = w0 * w1 * (mu1 - mu0) ** 2  #(equation 14)\n",
    "\n",
    "        if variance > max_variance: # find the maximum variance and corresponding threshold\n",
    "            max_variance = variance\n",
    "            threshold = i\n",
    "\n",
    "    return threshold\n",
    "\n",
    "\n",
    "#wrapper\n",
    "def otsu_segment(image):\n",
    "    threshold = otsu(image)\n",
    "    segmented_image = (image >= threshold).astype(np.uint8)\n",
    "    return segmented_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469b0210",
   "metadata": {},
   "source": [
    "## cleaning/denoising algorithm\n",
    "\n",
    "after reading the description i realised that you could basically just perform a convolution operation using a kernel to sum, and then choosing the class of the given pixel by using the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ee886dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoising_algorithm(image, relative_threshold, iterations = 1, BigNeighborhood = True):\n",
    "\n",
    "  neigborhood8 = np.array([\n",
    "        [1, 1, 1],\n",
    "        [1, 0, 1],\n",
    "        [1, 1, 1]\n",
    "    ])\n",
    "\n",
    "  neigborhood4 = np.array([\n",
    "        [0, 1, 0],\n",
    "        [1, 0, 1],\n",
    "        [0, 1, 0]\n",
    "    ])\n",
    "  \n",
    "  kernel = neigborhood8 if BigNeighborhood else neigborhood4 # choosing which neighborhood to use\n",
    "  max_votes = kernel.sum()\n",
    "\n",
    "  current_image = image.copy()\n",
    "\n",
    "  for _ in range(iterations):\n",
    "   \n",
    "    votes = convolve2d(current_image, kernel, mode='same', boundary='fill', fillvalue=0)  # returns the votes for each pixel\n",
    "\n",
    "    relative_votes = votes / max_votes\n",
    "\n",
    "    current_image = (relative_votes >= relative_threshold).astype(np.uint8) #update image based on voting threshold\n",
    "\n",
    "  return current_image\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fcceae",
   "metadata": {},
   "source": [
    "## Import and Feature extraction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bc8c6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_greyscale(path):\n",
    "    image = cv2.imread(path)\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    return gray_image\n",
    "\n",
    "def display_segmented_image(image):\n",
    "    cv2.imshow('image',image.astype(np.uint8) * 255)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d63ac8",
   "metadata": {},
   "source": [
    "# Import images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77df312d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#required images\n",
    "camera = load_image_greyscale(\"images/camera.png\")\n",
    "coins = load_image_greyscale(\"images/coins.png\")\n",
    "page = load_image_greyscale(\"images/page.png\")\n",
    "rocksample = load_image_greyscale(\"images/rocksample.png\")\n",
    "\n",
    "#optional image\n",
    "coronary = load_image_greyscale(\"images/coronary.jpg\")\n",
    "#taken from https://tedrogersresearch.ca/2021/11/coronary-angiography-a-tool-to-diagnose-cad-in-acute-heart-failure/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8a213a",
   "metadata": {},
   "source": [
    "## Perform segmentation and display segmentation: kmeans and Otsu\n",
    "* Create and run your implementations of k-means and Otsu on Absalonâ€™s images and\n",
    "one or more of your choice.\n",
    "* Comment on their similarity, dissimilarities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f98099b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Segment images\n",
    "#experiment variables:\n",
    "k = 2\n",
    "ex_random_seed = 41\n",
    "ex_patience = 2\n",
    "\n",
    "\n",
    "#camera\n",
    "camera_segmented_kmeans = kmeans_segment_binary(k ,camera, ex_random_seed, ex_patience)\n",
    "camera_segmented_otsu = otsu_segment(image= camera)\n",
    "\n",
    "#coins\n",
    "coins_segmented_kmeans = kmeans_segment_binary(k , coins, ex_random_seed, ex_patience)\n",
    "coins_segmented_otsu = otsu_segment(image= coins)\n",
    "\n",
    "\n",
    "\n",
    "# page\n",
    "page_segmented_kmeans = kmeans_segment_binary(k , page, ex_random_seed, ex_patience)\n",
    "page_segmented_otsu = otsu_segment(image= page)\n",
    "\n",
    "\n",
    "#rocksample\n",
    "rocksample_segmented_kmeans = kmeans_segment_binary(k ,rocksample, ex_random_seed, ex_patience)\n",
    "rocksample_segmented_otsu = otsu_segment(image= rocksample)\n",
    "\n",
    "\n",
    "#coronary\n",
    "coronary_segmented_kmeans = kmeans_segment_binary(k ,coronary, ex_random_seed, ex_patience)\n",
    "coronary_segmented_otsu = otsu_segment(image= coronary)\n",
    "\n",
    "#display images\n",
    "\n",
    "#camera\n",
    "display_segmented_image(camera_segmented_kmeans)\n",
    "display_segmented_image(camera_segmented_otsu)\n",
    "\n",
    "#coins\n",
    "display_segmented_image(coins_segmented_kmeans)\n",
    "display_segmented_image(coins_segmented_otsu)\n",
    "\n",
    "\n",
    "#page\n",
    "display_segmented_image(page_segmented_kmeans)\n",
    "display_segmented_image(page_segmented_otsu)\n",
    "\n",
    "\n",
    "#rocksample\n",
    "display_segmented_image(rocksample_segmented_kmeans)\n",
    "display_segmented_image(rocksample_segmented_otsu)\n",
    "\n",
    "\n",
    "#coronary\n",
    "display_segmented_image(coronary_segmented_kmeans)\n",
    "display_segmented_image(coronary_segmented_otsu)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2c8a93",
   "metadata": {},
   "source": [
    "## Perform denoising on segmented images\n",
    "* Run several iterations of the segmentation denoising algorithm with varying voting\n",
    "thresholds values. Comment on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b98dbbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Perform denoising\n",
    "# experiment variable\n",
    "ex_vote_threshold = 0.75\n",
    "ex_iterations = 2\n",
    "ex_BigNeighborhood = True\n",
    "\n",
    "#camera\n",
    "camera_denoised_kmeans = denoising_algorithm(camera_segmented_kmeans, ex_vote_threshold, ex_iterations \n",
    ", ex_BigNeighborhood)\n",
    "camera_denoised_otsu = denoising_algorithm(camera_segmented_otsu, ex_vote_threshold, ex_iterations\n",
    ", ex_BigNeighborhood)\n",
    "\n",
    "#coins\n",
    "coins_denoised_kmeans = denoising_algorithm(coins_segmented_kmeans, ex_vote_threshold, ex_iterations\n",
    ", ex_BigNeighborhood)\n",
    "coins_denoised_otsu = denoising_algorithm(coins_segmented_otsu, ex_vote_threshold, ex_iterations\n",
    ", ex_BigNeighborhood)\n",
    "\n",
    "#page\n",
    "page_denoised_kmeans = denoising_algorithm(page_segmented_kmeans, ex_vote_threshold, ex_iterations\n",
    ", ex_BigNeighborhood)\n",
    "page_denoised_otsu = denoising_algorithm(page_segmented_otsu, ex_vote_threshold, ex_iterations\n",
    ", ex_BigNeighborhood)\n",
    "\n",
    "#rocksample\n",
    "rocksample_denoised_kmeans = denoising_algorithm(rocksample_segmented_kmeans, ex_vote_threshold, ex_iterations\n",
    ", ex_BigNeighborhood)\n",
    "rocksample_denoised_otsu = denoising_algorithm(rocksample_segmented_otsu, ex_vote_threshold, ex_iterations\n",
    ", ex_BigNeighborhood)\n",
    "\n",
    "#coronary\n",
    "coronary_denoised_kmeans = denoising_algorithm(coronary_segmented_kmeans, ex_vote_threshold, ex_iterations\n",
    ", ex_BigNeighborhood)\n",
    "coronary_denoised_otsu = denoising_algorithm(coronary_segmented_otsu, ex_vote_threshold, ex_iterations\n",
    ", ex_BigNeighborhood)\n",
    "\n",
    "\n",
    "#display images\n",
    "\n",
    "#camera\n",
    "display_segmented_image(camera_denoised_kmeans)\n",
    "display_segmented_image(camera_denoised_otsu)\n",
    "\n",
    "#coins\n",
    "display_segmented_image(coins_segmented_kmeans)\n",
    "display_segmented_image(coins_segmented_otsu)\n",
    "\n",
    "\n",
    "#page\n",
    "display_segmented_image(page_denoised_kmeans)\n",
    "display_segmented_image(page_denoised_otsu)\n",
    "\n",
    "\n",
    "#rocksample\n",
    "display_segmented_image(rocksample_denoised_kmeans)\n",
    "display_segmented_image(rocksample_denoised_otsu)\n",
    "\n",
    "\n",
    "#coronary\n",
    "display_segmented_image(coronary_denoised_kmeans)\n",
    "display_segmented_image(coronary_denoised_otsu)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41412883",
   "metadata": {},
   "source": [
    "# kmeans on page image for k>2\n",
    "* Run a k-means segmentation with k > 2. Can it help with the page image?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b99dba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#page k =3\n",
    "page_segmented_kmeans3 = kmeans_segment(k =3 ,image = page, random_seed =42, patience = 2)\n",
    "display_segmented_image(page_segmented_kmeans3)\n",
    "\n",
    "#page k =4\n",
    "page_segmented_kmeans4 = kmeans_segment(k =4 ,image = page, random_seed =42, patience = 2)\n",
    "display_segmented_image(page_segmented_kmeans4)\n",
    "\n",
    "#page k =5\n",
    "page_segmented_kmeans5 = kmeans_segment(k =5 ,image = page, random_seed =42, patience = 2)\n",
    "display_segmented_image(page_segmented_kmeans5)\n",
    "\n",
    "#page k =8\n",
    "page_segmented_kmeans8 = kmeans_segment(k =8 ,image = page, random_seed =42, patience = 2)\n",
    "display_segmented_image(page_segmented_kmeans8)\n",
    "\n",
    "#page k =10\n",
    "page_segmented_kmeans10 = kmeans_segment(k =10 ,image = page, random_seed =42, patience = 2)\n",
    "display_segmented_image(page_segmented_kmeans10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41d3870",
   "metadata": {},
   "source": [
    "## Extra optional k-means experiment for coronary and rock-sample (Not used)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfb001b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#page k =3\n",
    "coronary_segmented_kmeans3 = kmeans_segment(k =3 ,image = coronary, random_seed =42, patience = 2)\n",
    "display_segmented_image(coronary_segmented_kmeans3)\n",
    "\n",
    "\n",
    "coronary_segmented_kmeans6 = kmeans_segment(k =6 ,image = coronary, random_seed =42, patience = 2)\n",
    "display_segmented_image(coronary_segmented_kmeans6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d5589a",
   "metadata": {},
   "source": [
    "# testing scikit-learn segmentation algorithms on the page image\n",
    "* You may want to try some of the algorithms available in scikit-learn, such as the\n",
    "Chan-Vese segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ff44340",
   "metadata": {},
   "outputs": [],
   "source": [
    "## chan vase segmentation\n",
    "#experiment variable\n",
    "ex_lambda1 = 1\n",
    "ex_lambda2 = 1\n",
    "ex_tol = 1e-3\n",
    "ex_max_num_iter = 200\n",
    "ex_extended_output = False\n",
    "\n",
    "# #camera\n",
    "camera_chan_vese_segmentation = chan_vese(image = camera,mu= 0.1, lambda1= ex_lambda1, lambda2=ex_lambda2, tol= ex_tol, max_num_iter= ex_max_num_iter, extended_output= ex_extended_output)\n",
    "display_segmented_image(camera_chan_vese_segmentation)\n",
    "\n",
    "\n",
    "#coins\n",
    "coins_chan_vese_segmentation = chan_vese(image = coins,mu= 0.01, lambda1= ex_lambda1, lambda2=ex_lambda2, tol= ex_tol, max_num_iter= ex_max_num_iter, extended_output= ex_extended_output)\n",
    "display_segmented_image(coins_chan_vese_segmentation)\n",
    "\n",
    "# #page\n",
    "page_chan_vese_segmentation = chan_vese(image = page,mu= 0.01, lambda1= ex_lambda1, lambda2=ex_lambda2, tol= ex_tol, max_num_iter= ex_max_num_iter, extended_output= ex_extended_output)\n",
    "display_segmented_image(page_chan_vese_segmentation)\n",
    "\n",
    "# #rock sample\n",
    "rocksample_chan_vese_segmentation = chan_vese(image = rocksample,mu= 0.005, lambda1= ex_lambda1, lambda2=ex_lambda2, tol= ex_tol, max_num_iter= ex_max_num_iter, extended_output= ex_extended_output)\n",
    "display_segmented_image(rocksample_chan_vese_segmentation)\n",
    "\n",
    "# #coronary\n",
    "coronary_chan_vese_segmentation = chan_vese(image = coronary,mu= 0.01, lambda1= ex_lambda1, lambda2=1, tol= ex_tol, max_num_iter= ex_max_num_iter, extended_output= ex_extended_output)\n",
    "display_segmented_image(coronary_chan_vese_segmentation)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VIP2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c700027e",
   "metadata": {},
   "source": [
    "## Libraries and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f91d41d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fc3c47",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4147b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 8677/8677 [00:02<00:00, 3396.78 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected labels: ['hawksbill', 'bonsai', 'laptop', 'panda', 'lobster']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ds_dict = load_dataset(\"flwrlabs/caltech101\")\n",
    "\n",
    "random.seed(47)\n",
    "\n",
    "ds = ds_dict[\"train\"]\n",
    "class_names = ds.features[\"label\"].names\n",
    "\n",
    "# sample 5 random label IDs\n",
    "num_of_labels = 5 # change as needed <--------------\n",
    "num_classes = len(class_names)\n",
    "selected_label_ids = random.sample(range(num_classes), num_of_labels) \n",
    "\n",
    "# filter dataset\n",
    "ds = ds.filter(lambda x: x[\"label\"] in selected_label_ids)\n",
    "\n",
    "# We map the ids to class names for printing so we know which labels were selected\n",
    "selected_labels = [class_names[i] for i in selected_label_ids]\n",
    "print(\"Selected labels:\", selected_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1621ead1",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7c18637",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_split = ds.train_test_split(test_size=0.5, seed=42) # define split, it puts the remaining data in \"train\"\n",
    "\n",
    "train_ds = ds_split[\"train\"] # training set #50% of data\n",
    "test_ds  = ds_split[\"test\"] # test set #50% of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cfc28a",
   "metadata": {},
   "source": [
    "## Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b686b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "sift = cv2.SIFT_create() #SIFT feature extractor, create the SIFT object once\n",
    "\n",
    "def extract_features(pil_image):\n",
    "\n",
    "    # Convert PIL image to numpy array\n",
    "    image = np.array(pil_image)\n",
    "\n",
    "    # Convert to grayscale\n",
    "    if image.ndim == 3:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    #extract_features\n",
    "    keypoints, descriptors = sift.detectAndCompute(image, None)\n",
    "\n",
    "    # Handle images with no keypoints\n",
    "    if descriptors is None:\n",
    "        return np.empty((0, 128), dtype=np.float32)\n",
    "\n",
    "    return keypoints ,descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad864cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((87407, 128), (82923, 128))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features = []\n",
    "train_labels   = []\n",
    "for sample in train_ds:\n",
    "    keypoints, descriptors = extract_features(sample[\"image\"])\n",
    "    train_features.append(descriptors)\n",
    "    train_labels.append(sample[\"label\"])\n",
    "\n",
    "\n",
    "test_features = []\n",
    "test_labels   = []\n",
    "for sample in test_ds:\n",
    "    keypoints, descriptors = extract_features(sample[\"image\"])\n",
    "    test_features.append(descriptors)\n",
    "    test_labels.append(sample[\"label\"])\n",
    "\n",
    "# Convert lists to matrix\n",
    "train_feature_matrix = np.vstack(train_features)\n",
    "test_feature_matrix = np.vstack(test_features)\n",
    "\n",
    "train_feature_matrix.shape, test_feature_matrix.shape #check shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a63748c",
   "metadata": {},
   "source": [
    "The shape above tells us that we currently have 87407 (rows) features represented as vectors of length 128. Each feature describes a patch in a given image in the dataset. A feature could fx. be a pattern, blob, corner, edge or something else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d1c74fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 128)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sample some of the descriptors, to reduce size for k-means\n",
    "num_samples = 1000  # Adjust as needed\n",
    "\n",
    "num_dec = train_feature_matrix.shape[0]\n",
    "sample_size = min(num_samples, num_dec) # so we dont sample more than we have\n",
    "\n",
    "rng = np.random.default_rng(seed=42)  # set random seed\n",
    "sample_indices = rng.choice(num_dec, size=sample_size, replace=False)\n",
    "\n",
    "\n",
    "\n",
    "train_sampled_descriptors = train_feature_matrix[sample_indices] # for train\n",
    "train_sampled_descriptors.shape #check shapes again"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb2bee8",
   "metadata": {},
   "source": [
    "## K mens clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5023bd69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marcus\\.conda\\envs\\VIP\\Lib\\site-packages\\threadpoolctl.py:1214: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "c:\\Users\\Marcus\\.conda\\envs\\VIP\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "k = 500  # number of clusters / visual words\n",
    "random_state = 42\n",
    "KMeans_model = sklearn.cluster.KMeans(n_clusters=k, random_state=random_state, n_init= 10) # Model definition\n",
    "KMeans_model.fit(train_sampled_descriptors) # Fit model, which means to train the k-means clustering\n",
    "visual_words = KMeans_model.cluster_centers_  # The cluster centers are our visual words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d923399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visual words shape: (500, 128)\n",
      "Inertia: 28151216.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Visual words shape:\", visual_words.shape)\n",
    "print(\"Inertia:\", KMeans_model.inertia_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b13a366",
   "metadata": {},
   "source": [
    "## Form Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c579f56c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VIP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c700027e",
   "metadata": {},
   "source": [
    "## Libraries and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91d41d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fc3c47",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4147b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dict = load_dataset(\"flwrlabs/caltech101\")\n",
    "\n",
    "random.seed(47)\n",
    "\n",
    "ds = ds_dict[\"train\"]\n",
    "class_names = ds.features[\"label\"].names\n",
    "\n",
    "# sample 5 random label IDs\n",
    "num_of_labels = 20 # change as needed <--------------\n",
    "num_classes = len(class_names)\n",
    "selected_label_ids = random.sample(range(num_classes), num_of_labels) \n",
    "\n",
    "# filter dataset\n",
    "ds = ds.filter(lambda x: x[\"label\"] in selected_label_ids)\n",
    "\n",
    "# We map the ids to class names for printing so we know which labels were selected\n",
    "selected_labels = [class_names[i] for i in selected_label_ids]\n",
    "print(\"Selected labels:\", selected_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1621ead1",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c18637",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_split = ds.train_test_split(test_size=0.5, seed=42) # define split, it puts the remaining data in \"train\"\n",
    "\n",
    "train_ds = ds_split[\"train\"] # training set #50% of data\n",
    "test_ds  = ds_split[\"test\"] # test set #50% of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe99fab",
   "metadata": {},
   "source": [
    "# 1 Codebook generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cfc28a",
   "metadata": {},
   "source": [
    "## Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b686b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "sift = cv2.SIFT_create() #SIFT feature extractor, create the SIFT object once\n",
    "\n",
    "def extract_features(pil_image):\n",
    "\n",
    "    # Convert PIL image to numpy array\n",
    "    image = np.array(pil_image)\n",
    "\n",
    "    # Convert to grayscale\n",
    "    if image.ndim == 3:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    #extract_features\n",
    "    keypoints, descriptors = sift.detectAndCompute(image, None)\n",
    "\n",
    "    # Handle images with no keypoints\n",
    "    if descriptors is None:\n",
    "        return np.empty((0, 128), dtype=np.float32)\n",
    "\n",
    "    return keypoints ,descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad864cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = []\n",
    "train_labels   = []\n",
    "for sample in train_ds:\n",
    "    keypoints, descriptors = extract_features(sample[\"image\"])\n",
    "    train_features.append(descriptors)\n",
    "    train_labels.append(sample[\"label\"])\n",
    "\n",
    "\n",
    "test_features = []\n",
    "test_labels   = []\n",
    "for sample in test_ds:\n",
    "    keypoints, descriptors = extract_features(sample[\"image\"])\n",
    "    test_features.append(descriptors)\n",
    "    test_labels.append(sample[\"label\"])\n",
    "\n",
    "# Convert lists to matrix\n",
    "train_feature_matrix = np.vstack(train_features) # use for training k-means\n",
    "test_feature_matrix = np.vstack(test_features)\n",
    "\n",
    "train_feature_matrix.shape, test_feature_matrix.shape #check shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a63748c",
   "metadata": {},
   "source": [
    "The shape above tells us that we currently have 87407 (rows) features represented as vectors of length 128. Each feature describes a patch in a given image in the dataset. A feature could fx. be a pattern, blob, corner, edge or something else."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948a69e6",
   "metadata": {},
   "source": [
    "### Reduce number of features (maybe not neccesary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c74fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample some of the descriptors, to reduce size for k-means\n",
    "num_samples = 1000  # Adjust as needed\n",
    "\n",
    "num_dec = train_feature_matrix.shape[0]\n",
    "sample_size = min(num_samples, num_dec) # so we dont sample more than we have\n",
    "\n",
    "rng = np.random.default_rng(seed=42)  # set random seed\n",
    "sample_indices = rng.choice(num_dec, size=sample_size, replace=False) # get random indices\n",
    "\n",
    "\n",
    "\n",
    "train_sampled_descriptors = train_feature_matrix[sample_indices] # get the randomly sampled descriptors\n",
    "train_sampled_descriptors.shape #check shapes again to make sure sampling worked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb2bee8",
   "metadata": {},
   "source": [
    "## K mens clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5023bd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 500  # number of clusters / visual words\n",
    "random_state = 42\n",
    "KMeans_model = sklearn.cluster.KMeans(n_clusters=k, random_state=random_state, n_init= 10) # Model definition\n",
    "KMeans_model.fit(train_sampled_descriptors) # Fit model, which means to train the k-means clustering\n",
    "codebook = KMeans_model.cluster_centers_  # The cluster centers are our visual words (our codebook)\n",
    "print(\"Visual words shape:\", codebook.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b13a366",
   "metadata": {},
   "source": [
    "## Form Bag of visual words for training data\n",
    "classify each training descriptor to the\n",
    "closest cluster centers and form the bag of words (BoW) for each image in the\n",
    "image training set. For each image, we find out which words appears, and how many times it appears. Remember that the Bag of visual words, IS the word histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c579f56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Which visual word (cluster) does each descriptor belong to?\n",
    "train_word_ids = []\n",
    "\n",
    "for descriptors in train_features:   # one image at a time\n",
    "    word_ids = KMeans_model.predict(descriptors)\n",
    "    train_word_ids.append(word_ids)\n",
    "\n",
    "# Now we can build the bag-of-words histograms for each image, i.e. \n",
    "#count how many times each visual word appears in the image\n",
    "train_bow = []\n",
    "for word_ids in train_word_ids:\n",
    "    hist = np.bincount(word_ids, minlength=k)\n",
    "    train_bow.append(hist)\n",
    "\n",
    "train_bow = np.array(train_bow)\n",
    "train_bow.shape  # Check shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eabaf90",
   "metadata": {},
   "source": [
    "# 2 Indexing\n",
    "For each image in the test set:\n",
    "\n",
    "* Extract the SIFT descriptors of the feature points in the image, (DONE)\n",
    "* Project the descriptors onto the codebook, i.e. for each descriptor the find the closest cluster\n",
    "* Constructs the generated corresponding bag of words, i.e. word histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4613af",
   "metadata": {},
   "source": [
    "## Form the bag of words for the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d586c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Which visual word (cluster) does each descriptor belong to?\n",
    "test_word_ids = []\n",
    "\n",
    "for descriptors in test_features:   # one image at a time\n",
    "    word_ids = KMeans_model.predict(descriptors)\n",
    "    test_word_ids.append(word_ids)\n",
    "# Now we can build the bag-of-words histograms for each image, i.e. \n",
    "#count how many times each visual word appears in the image\n",
    "test_bow = []\n",
    "for word_ids in test_word_ids:\n",
    "    hist = np.bincount(word_ids, minlength=k)\n",
    "    test_bow.append(hist)\n",
    "\n",
    "test_bow = np.array(test_bow)\n",
    "test_bow.shape  # Check shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8190ad40",
   "metadata": {},
   "source": [
    "## Construct table\n",
    "Per row the table should contain\n",
    "* file name\n",
    "* true category\n",
    "* training or test set\n",
    "* corresponding bag of words/word histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067ae957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training DataFrame\n",
    "train_rows = []\n",
    "\n",
    "for i, sample in enumerate(train_ds):\n",
    "    row = {\n",
    "        \"filename\": sample.get(\"filename\", f\"train_{i}\"),\n",
    "        \"label\": train_labels[i],\n",
    "        \"split\": \"train\",\n",
    "        \"bow\": train_bow[i]\n",
    "    }\n",
    "    train_rows.append(row)\n",
    "\n",
    "train_table = pd.DataFrame(train_rows)\n",
    "\n",
    "# Create test DataFrame\n",
    "test_rows = []\n",
    "\n",
    "for i, sample in enumerate(test_ds):\n",
    "    row = {\n",
    "        \"filename\": sample.get(\"filename\", f\"test_{i}\"),\n",
    "        \"label\": test_labels[i],\n",
    "        \"split\": \"test\",\n",
    "        \"bow\": test_bow[i]\n",
    "    }\n",
    "    test_rows.append(row)\n",
    "\n",
    "test_table = pd.DataFrame(test_rows)\n",
    "\n",
    "# Combine the two :)\n",
    "Table = pd.concat([train_table, test_table], ignore_index=True)\n",
    "print(\"Combined table shape: images x categories\", Table.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VIP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
